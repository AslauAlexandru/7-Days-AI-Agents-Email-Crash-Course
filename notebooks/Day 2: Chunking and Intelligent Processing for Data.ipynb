{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729980cd",
   "metadata": {},
   "source": [
    "# Day 2: Chunking and Intelligent Processing for Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49b1af40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evidently documents: 95\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n",
    "\n",
    "\n",
    "\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c7eacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d75efd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    evidently_chunks.extend(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b47e800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = evidently_docs[45]['content']\n",
    "paragraphs = re.split(r\"\\n\\s*\\n\", text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98ca42a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "    \n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbc30b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = split_markdown_by_level(text, level=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11674c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        evidently_chunks.append(section_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52ac6dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# print(os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f58fcf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")\n",
    "\n",
    "def llm(prompt, model=\"llama-3.3-70b-versatile\"):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling LLM: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b783e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Split the provided document into logical sections\n",
    "that make sense for a Q&A system.\n",
    "\n",
    "Each section should be self-contained and cover\n",
    "a specific topic or concept.\n",
    "\n",
    "<DOCUMENT>\n",
    "{document}\n",
    "</DOCUMENT>\n",
    "\n",
    "Use this format:\n",
    "\n",
    "## Section Name\n",
    "\n",
    "Section content with all relevant details\n",
    "\n",
    "---\n",
    "\n",
    "## Another Section Name\n",
    "\n",
    "Another section content\n",
    "\n",
    "---\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62100976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intelligent_chunking(text):\n",
    "    prompt = prompt_template.format(document=text)\n",
    "    response = llm(prompt)\n",
    "    sections = response.split('---')\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfa15cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb38f3b572494b3691ae451dd2093d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99929, Requested 1592. Please try again in 21m54.114s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99929, Requested 2699. Please try again in 37m50.535s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 99929, Requested 1313. Please try again in 17m53.002999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 108. Please try again in 5m2.351s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 95. Please try again in 4m51.09s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 100. Please try again in 4m55.381s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 98. Please try again in 4m53.626s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 93. Please try again in 4m49.277s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 518. Please try again in 10m56.444s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 8056. Please try again in 1h59m29.249999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 13838. Please try again in 3h22m44.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 372. Please try again in 8m50.207s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 96. Please try again in 4m51.709s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 96. Please try again in 4m51.681s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 4552. Please try again in 1h9m1.634999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 979. Please try again in 17m34.533s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 5503. Please try again in 1h22m43.238s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 2773. Please try again in 43m24.394s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 6772. Please try again in 1h40m59.5s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 1128. Please try again in 19m43.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 2095. Please try again in 33m38.506999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 1971. Please try again in 31m51.343999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 2183. Please try again in 34m54.482999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 87. Please try again in 4m43.508999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 2632. Please try again in 41m22.356s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 2425. Please try again in 38m23.468s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100241, Requested 321. Please try again in 8m5.587s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 1080. Please try again in 19m1.331s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 1504. Please try again in 25m7.636s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 1061. Please try again in 18m44.852999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 867. Please try again in 15m57.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 955. Please try again in 17m13.21s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 930. Please try again in 16m51.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 2494. Please try again in 39m22.839s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 1814. Please try again in 29m35.292s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 1574. Please try again in 26m7.903s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 181. Please try again in 6m4.324s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 190. Please try again in 6m12.068999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 718. Please try again in 13m48.228s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 575. Please try again in 11m44.648999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 406. Please try again in 9m18.607s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 587. Please try again in 11m54.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n",
      "Error calling LLM: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01ja956188etvtj5n7j4x43ecc` service tier `on_demand` on tokens per day (TPD): Limit 100000, Used 100240, Requested 611. Please try again in 12m15.663s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "evidently_chunks = []\n",
    "\n",
    "for doc in tqdm(evidently_docs):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        evidently_chunks.append(section_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95455516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15d235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84734ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "7-days-ai-agents-email-crash-course (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
